## [Elasticsearch](https://www.elastic.co/products/elasticsearch)
### Основные сведения
* Узел - один сервер Elasticsearch (далее - ES).
* Кластер - несколько серверов elasticsearch которые хранят и индексирует один набор данных. Принадлежность узла кластеру определяется именем кластера в настройках узла (по умолчанию все узлы сети присоединяться к кластеру elasticsearch).
* Документ - единица хранения и поиска, состоящая из набора полей и связанных с ними данных.
* Индекс - набор документов (аналог имени БД). То есть добавление данных (документов) в ES и их поиск производится в индекс и в индексе соответственно. При этом сильной стороной ES является то, что поиск может осуществляться в нескольких или даже во всех имеющихся в кластере ES индексах.
* Тип - категория документа в индексе (аналог таблицы БД). В одном индексе может быть только один тип. В будущем он будет изъят из ES.
* Мэпинг (mapping) - информация о том, к какому типу данных Elasticsearch относится значение поля (аналог схемы с типами данных в БД). Mapping создается автоматически при создании индекса. У каждого типа свой mapping.
* Шард - Индекс разбивается на шарды, соответственно шард это часть индекса (как набора документов). Шарды одного индекса могут обрабатываться на разных узлах, что позволяет масштабировать систему.
* Реплика – копия шарда, которая может обрабатываться на другом узле и обеспечивать отказоустойчивость.
### Установка
Установка производится согласно [официальной документации](https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html)
#### Сбор информации о состоянии elasticsearch
Общая информация об узле
```shell
curl localhost:9200
```
Перечень доступных диагностических полей
```shell
curl localhost:9200/_cat
```
Индексы узла
```shell
curl localhost:9200/_cat/indices?v
```
Состояние работоспособности
```shell
curl localhost:9200/_cat/health?v
```
### Добавление и удаление данных
Управление elasticsearch и манипулирование его данными осуществляется с помощью с [REST](https://ru.wikipedia.org/wiki/REST).

Создать индекс
```shell
curl -XPUT localhost:9200/<индекс>
```
Если после индекс задать параметр pretty (localhost:9200/индекс?pretty) то ответ сервера будет в читабельном виде.
Добавить документ в индекс
```shell
curl -XPUT localhost:9200/<индекс>/<тип>/1 {"поле": "значение"}
```
где **1** это **id** документа, если его не указать, он будет сгенерирован как случайное значение.

Если индекс предварительно не существовал, он будет создан при добавлении документа.

Для замены документа, достаточно добавить в индекс документ с id редактируемого документа.

Обновление документа (можно обновлять и добавлять поля):
```shell
curl -XPOST "localhost:9200/<индекс>/<тип>/1/_update" -d "
{ "doc":
  { "поле" :"значение"}
}"
```
Получить документ
```shell
curl -XGET localhost:9200/<индекс>/<тип>/1
```
Удалить документ (можно несколько, через запрос)
```shell
curl -XDEL localhost:9200/<индекс>/<тип>/1/_
```
Удалить все индексы (вместе с документами)
```shell
curl -XDELETE localhost:9200/_all
```
Пакетная обработка (выполнение нескольких манипуляций с данными в одном HTTP запросе)
```shell
curl -XPOST localhost:9200/<индекс>/<тип>/_bulk {запрос}
```
Дынные (json) могут быть переданы в запрос через файл
```shell
curl -XPOST localhost:9200/<индекс>/<тип>/_bulk --data-binary файл
```
### Поиск данных
#### Осноные служебные поля
Поля которые начинаются с символа **_** являются служебными (например, _source).

В поле **_source** содержится исходный (индексируемый) документ (json объект).

В поле **_version** содержится номер версии документа.
> Поиск, фильтрацию, сортировку и прочие вещи, связанные с анализом данных, лучше выполнять не через curl (описано) ниже, а через [Kibana](./kibana.md)

#### Запросы
Запросы бывают в двух контекстах:
* query (запрос) - рассчитывает релевантность найденных документов (_score)
* filter (фильтрация) - релевантность не рассчитывается, документы не соответствующие фильтру не попадают в ответ

Указанные выше контексты могут использоваться в одном запросе.

Для поиска данных используется Query DSL.

Запрос всех документов (по умолчанию выдаются первые 10 результатов)
```shell
curl localhost:9200/<индекс>/_search?q=*
```
или
```shell
curl -XPOST -H 'Content-Type: application/json" "localhost:9200/<индекс>/_search" -d "
{
  "query": { "match_all": {} }
}"
```
> в имени индекса, в типе, а также в именах и значениях полей можно использовать символ *, который соответствует любым символам


#### Основные параметры запроса
Начиная с какой записи возвращать документы (аналог OFFSET в БД)
```shell
"from": 10
```
Количество возвращаемых документов (аналог LIMIT в БД)
```shell
"size": 10
```
Поиск документов, поле которых удовлетворяет условию:
```shell
{
"query": { "match": { "поле": <значение> } }
}'
```
Где значение может содержать несколько термов (осуществляет поиск совпадения с любым из них)

"терм терм2 терм3"

Для поиска совпадения по фразе вместо match используется match_phrase.

В этом случае ES будет искать совпадение с фразой ("терм терм2 терм3").

Логический запрос (**bool**)
```shell
{
  "query": {
    "bool": {
      "условие": [
        { "match": { "<поле1>": "<значение1>" } },
        { "match": { "<поле2>": "<значение2>" } }
      ]
    }
  }
}
```
Где условие может быть
* must - И
* should - ИЛИ
* not_must - НЕ
### Фильтрация
Запросы с помощью фильтрации выполняются быстрее и они кэшируются, но при таких запросах не происходит расчет релевантности документа запросу.

### Сортировка
Сортировать возвращаемые документы по указанному полю
```shell
"sort": { "поле": { "order": "desc" } }
```
### Агрегирование

### Администрирование
По умолчанию elasticearch работает на порту 9200 (HTTP).
###  Резервное копирование
Создать резервную копию данных
```bash
curl -XPUT "localhost:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true"
```
Восстановить данные из резервной копии
```bash
curl -XPOST "localhost:9200/_snapshot/my_backup/snapshot_1/_restore"
```
